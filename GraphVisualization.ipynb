{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Psychology Classic Books.xlsx\", sheet_name= 1,  dtype={'Title': str,'Original Publication Year': object,'Author': str,'Summary': str,'Keywords': str,'Additional Keywords': str,'Average Rating': float, 'Number of Pages': float, 'Publisher': str, 'ISBN': str, 'ISBN13' : str, 'Themes' : str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Original Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Additional Keywords</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>Themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Understanding Human Nature</td>\n",
       "      <td>1927</td>\n",
       "      <td>Alfred Adler</td>\n",
       "      <td>Originally published in 1927 this book attempt...</td>\n",
       "      <td>inferiority complex, character</td>\n",
       "      <td>development, goal</td>\n",
       "      <td>3.96</td>\n",
       "      <td>224.0</td>\n",
       "      <td>Fawcett</td>\n",
       "      <td>449308332</td>\n",
       "      <td>9780449308332</td>\n",
       "      <td>developmental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Nature of Prejudice</td>\n",
       "      <td>1954</td>\n",
       "      <td>Gordon W. Allport</td>\n",
       "      <td>With profound insight into the complexities of...</td>\n",
       "      <td>prejudice, race, discrimination</td>\n",
       "      <td>violence, rationality</td>\n",
       "      <td>4.24</td>\n",
       "      <td>575.0</td>\n",
       "      <td>Basic Books</td>\n",
       "      <td>201001799</td>\n",
       "      <td>9780201001792</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-Efficacy: The Exercise of Control</td>\n",
       "      <td>1997</td>\n",
       "      <td>Albert Bandura</td>\n",
       "      <td>With over 20 years of research by renowned psy...</td>\n",
       "      <td>self-system, self-esteem, self-efficacy</td>\n",
       "      <td>goal, self</td>\n",
       "      <td>4.12</td>\n",
       "      <td>604.0</td>\n",
       "      <td>Worth Publishers</td>\n",
       "      <td>716728508</td>\n",
       "      <td>9780716728504</td>\n",
       "      <td>behavioural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Gift of Fear: Survival Signals That Protec...</td>\n",
       "      <td>1997</td>\n",
       "      <td>Gavin de Becker</td>\n",
       "      <td>A date won't take \"no\" for an answer. The new ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>violence, intuition, crime</td>\n",
       "      <td>4.18</td>\n",
       "      <td>352.0</td>\n",
       "      <td>Bloomsbury Publishing PLC</td>\n",
       "      <td>747538352</td>\n",
       "      <td>9780747538356</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Games People Play</td>\n",
       "      <td>1964</td>\n",
       "      <td>Eric Berne</td>\n",
       "      <td>Forty years ago, Games People Play revolutioni...</td>\n",
       "      <td>stroke, transactional analysis, games</td>\n",
       "      <td>social</td>\n",
       "      <td>3.74</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>345032799</td>\n",
       "      <td>9780345032799</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                         Understanding Human Nature   \n",
       "1                            The Nature of Prejudice   \n",
       "2             Self-Efficacy: The Exercise of Control   \n",
       "3  The Gift of Fear: Survival Signals That Protec...   \n",
       "4                                  Games People Play   \n",
       "\n",
       "  Original Publication Year             Author  \\\n",
       "0                      1927       Alfred Adler   \n",
       "1                      1954  Gordon W. Allport   \n",
       "2                      1997     Albert Bandura   \n",
       "3                      1997    Gavin de Becker   \n",
       "4                      1964         Eric Berne   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Originally published in 1927 this book attempt...   \n",
       "1  With profound insight into the complexities of...   \n",
       "2  With over 20 years of research by renowned psy...   \n",
       "3  A date won't take \"no\" for an answer. The new ...   \n",
       "4  Forty years ago, Games People Play revolutioni...   \n",
       "\n",
       "                                  Keywords         Additional Keywords  \\\n",
       "0           inferiority complex, character           development, goal   \n",
       "1          prejudice, race, discrimination       violence, rationality   \n",
       "2  self-system, self-esteem, self-efficacy                  goal, self   \n",
       "3                                     fear  violence, intuition, crime   \n",
       "4    stroke, transactional analysis, games                      social   \n",
       "\n",
       "   Average Rating  Number of Pages                  Publisher       ISBN  \\\n",
       "0            3.96            224.0                    Fawcett  449308332   \n",
       "1            4.24            575.0                Basic Books  201001799   \n",
       "2            4.12            604.0           Worth Publishers  716728508   \n",
       "3            4.18            352.0  Bloomsbury Publishing PLC  747538352   \n",
       "4            3.74            192.0                    Penguin  345032799   \n",
       "\n",
       "          ISBN13         Themes  \n",
       "0  9780449308332  developmental  \n",
       "1  9780201001792         social  \n",
       "2  9780716728504    behavioural  \n",
       "3  9780747538356         social  \n",
       "4  9780345032799         social  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert number of pages to int.\n",
    "#Use Int64 for NaN support: https://stackoverflow.com/a/70548802\n",
    "import math\n",
    "df[\"Number of Pages\"] = df[\"Number of Pages\"].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                         object\n",
       "Original Publication Year     object\n",
       "Author                        object\n",
       "Summary                       object\n",
       "Keywords                      object\n",
       "Additional Keywords           object\n",
       "Average Rating               float64\n",
       "Number of Pages                Int64\n",
       "Publisher                     object\n",
       "ISBN                          object\n",
       "ISBN13                        object\n",
       "Themes                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the additional keywords column into a connection.\n",
    "\n",
    "Create a function that appplies to each row of the dataframe. For the additional keywords column, if other rows also contains the keywords then increase the strength of connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Original Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Additional Keywords</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>Themes</th>\n",
       "      <th>Additional Keywords List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Understanding Human Nature</td>\n",
       "      <td>1927</td>\n",
       "      <td>Alfred Adler</td>\n",
       "      <td>Originally published in 1927 this book attempt...</td>\n",
       "      <td>inferiority complex, character</td>\n",
       "      <td>development, goal</td>\n",
       "      <td>3.96</td>\n",
       "      <td>224</td>\n",
       "      <td>Fawcett</td>\n",
       "      <td>449308332</td>\n",
       "      <td>9780449308332</td>\n",
       "      <td>developmental</td>\n",
       "      <td>[development, goal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Nature of Prejudice</td>\n",
       "      <td>1954</td>\n",
       "      <td>Gordon W. Allport</td>\n",
       "      <td>With profound insight into the complexities of...</td>\n",
       "      <td>prejudice, race, discrimination</td>\n",
       "      <td>violence, rationality</td>\n",
       "      <td>4.24</td>\n",
       "      <td>575</td>\n",
       "      <td>Basic Books</td>\n",
       "      <td>201001799</td>\n",
       "      <td>9780201001792</td>\n",
       "      <td>social</td>\n",
       "      <td>[violence, rationality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-Efficacy: The Exercise of Control</td>\n",
       "      <td>1997</td>\n",
       "      <td>Albert Bandura</td>\n",
       "      <td>With over 20 years of research by renowned psy...</td>\n",
       "      <td>self-system, self-esteem, self-efficacy</td>\n",
       "      <td>goal, self</td>\n",
       "      <td>4.12</td>\n",
       "      <td>604</td>\n",
       "      <td>Worth Publishers</td>\n",
       "      <td>716728508</td>\n",
       "      <td>9780716728504</td>\n",
       "      <td>behavioural</td>\n",
       "      <td>[goal, self]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Gift of Fear: Survival Signals That Protec...</td>\n",
       "      <td>1997</td>\n",
       "      <td>Gavin de Becker</td>\n",
       "      <td>A date won't take \"no\" for an answer. The new ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>violence, intuition, crime</td>\n",
       "      <td>4.18</td>\n",
       "      <td>352</td>\n",
       "      <td>Bloomsbury Publishing PLC</td>\n",
       "      <td>747538352</td>\n",
       "      <td>9780747538356</td>\n",
       "      <td>social</td>\n",
       "      <td>[violence, intuition, crime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Games People Play</td>\n",
       "      <td>1964</td>\n",
       "      <td>Eric Berne</td>\n",
       "      <td>Forty years ago, Games People Play revolutioni...</td>\n",
       "      <td>stroke, transactional analysis, games</td>\n",
       "      <td>social</td>\n",
       "      <td>3.74</td>\n",
       "      <td>192</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>345032799</td>\n",
       "      <td>9780345032799</td>\n",
       "      <td>social</td>\n",
       "      <td>[social]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                         Understanding Human Nature   \n",
       "1                            The Nature of Prejudice   \n",
       "2             Self-Efficacy: The Exercise of Control   \n",
       "3  The Gift of Fear: Survival Signals That Protec...   \n",
       "4                                  Games People Play   \n",
       "\n",
       "  Original Publication Year             Author  \\\n",
       "0                      1927       Alfred Adler   \n",
       "1                      1954  Gordon W. Allport   \n",
       "2                      1997     Albert Bandura   \n",
       "3                      1997    Gavin de Becker   \n",
       "4                      1964         Eric Berne   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Originally published in 1927 this book attempt...   \n",
       "1  With profound insight into the complexities of...   \n",
       "2  With over 20 years of research by renowned psy...   \n",
       "3  A date won't take \"no\" for an answer. The new ...   \n",
       "4  Forty years ago, Games People Play revolutioni...   \n",
       "\n",
       "                                  Keywords         Additional Keywords  \\\n",
       "0           inferiority complex, character           development, goal   \n",
       "1          prejudice, race, discrimination       violence, rationality   \n",
       "2  self-system, self-esteem, self-efficacy                  goal, self   \n",
       "3                                     fear  violence, intuition, crime   \n",
       "4    stroke, transactional analysis, games                      social   \n",
       "\n",
       "   Average Rating  Number of Pages                  Publisher       ISBN  \\\n",
       "0            3.96              224                    Fawcett  449308332   \n",
       "1            4.24              575                Basic Books  201001799   \n",
       "2            4.12              604           Worth Publishers  716728508   \n",
       "3            4.18              352  Bloomsbury Publishing PLC  747538352   \n",
       "4            3.74              192                    Penguin  345032799   \n",
       "\n",
       "          ISBN13         Themes      Additional Keywords List  \n",
       "0  9780449308332  developmental           [development, goal]  \n",
       "1  9780201001792         social       [violence, rationality]  \n",
       "2  9780716728504    behavioural                  [goal, self]  \n",
       "3  9780747538356         social  [violence, intuition, crime]  \n",
       "4  9780345032799         social                      [social]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the additional keywords into a list. Make sure each element is lowercase\n",
    "df[\"Additional Keywords List\"] = df[\"Additional Keywords\"].str.split(\",\").apply(lambda x: [s.lower().strip() for s in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biology', 'compliance', 'crime', 'determinism', 'development', 'disorder', 'free will', 'goal', 'happiness', 'intelligence', 'intuition', 'marriage', 'nature', 'neuroticism', 'personality', 'prejudice', 'psychoanalysis', 'rationality', 'repression', 'self', 'social', 'success', 'therapy', 'thought', 'thoughts', 'violence']\n"
     ]
    }
   ],
   "source": [
    "#Get the unique values in additional keywords list\n",
    "\n",
    "setKeywords = set()\n",
    "\n",
    "#Looping through the array and adding new keywords not seen.\n",
    "for idx, row in df.iterrows():\n",
    "    lst = row[\"Additional Keywords List\"]\n",
    "    for keyword in lst:\n",
    "        if not keyword in setKeywords:\n",
    "            setKeywords.add(keyword)\n",
    "\n",
    "listKeywords = list(setKeywords)\n",
    "listKeywords.sort()\n",
    "print(listKeywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biology', 'compliance', 'crime', 'determinism', 'development', 'disorder', 'free will', 'goal', 'happiness', 'intelligence', 'intuition', 'marriage', 'nature', 'neuroticism', 'personality', 'prejudice', 'psychoanalysis', 'rationality', 'repression', 'self', 'social', 'success', 'therapy', 'thought', 'thoughts', 'violence']\n",
      "[False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True]\n",
      "[False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False]\n",
      "[False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False]\n",
      "[False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False]\n",
      "[False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False]\n",
      "[False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False]\n",
      "[False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False]\n",
      "[False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False]\n",
      "[False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True]\n",
      "[False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False]\n",
      "[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False]\n",
      "[False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False]\n",
      "[False, False, False, True, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[True, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False]\n",
      "[False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[True, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False]\n",
      "[False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "#Count the occurence of keywords for each row\n",
    "#Outer list is the size of the number of observations\n",
    "occurrence = [False] * df.shape[0]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    lst = row[\"Additional Keywords List\"]\n",
    "\n",
    "    newOccurrenceRow = [False] * len(listKeywords)\n",
    "    #Inner list is the size of the keywords. \n",
    "    for keyIdx, keyword in enumerate(listKeywords):\n",
    "        if keyword in lst:\n",
    "            newOccurrenceRow[keyIdx] = True\n",
    "    \n",
    "    occurrence[idx] = newOccurrenceRow\n",
    "print(listKeywords)\n",
    "# for i in occurrence:\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This option will create wasterd space since the matrix will be symmetrical on the diagonal. \n",
    "#Outer array to contain the strength of connection between different rows. \n",
    "# strengthMatrix = [None] * df.shape[0]\n",
    "\n",
    "\n",
    "# for idx, occurRow in enumerate(occurrence):\n",
    "\n",
    "#     #This will contain the strength of the row with other rows. \n",
    "#     newStrengthRow = [None] * df.shape[0] \n",
    "#     # Look for the other occurRows\n",
    "#     for idx1, occurRow1 in enumerate(occurrence):\n",
    "\n",
    "#         #Only look at other rows. Only fill top half of the matrix (it is symmetrical on the diagonal)\n",
    "#         if idx != idx1 and idx1 > idx:\n",
    "#             strength = sum(np.array(occurRow) & np.array(occurRow1))\n",
    "#             newStrengthRow[idx1] = strength\n",
    "        \n",
    "#     strengthMatrix[idx] = newStrengthRow\n",
    "\n",
    "\n",
    "# for i in strengthMatrix:\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 3, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2]\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2]\n",
      "[0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1]\n",
      "[1, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1]\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1]\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0]\n",
      "[0, 0, 2, 1, 0, 0, 0, 0, 2, 0]\n",
      "[0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 1, 0]\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 2]\n",
      "[1, 0, 0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Outer array to contain the strength of connection between different rows. \n",
    "strengthMatrix = [None] * df.shape[0]\n",
    "\n",
    "\n",
    "for idx, occurRow in enumerate(occurrence):\n",
    "\n",
    "    #This will contain the strength of the row with other rows. \n",
    "    #Since the matrix will be symmetrical across the diagonal, we only fill one side of the matrix. \n",
    "    newStrengthRow = [None] * (df.shape[0] - idx - 1)\n",
    "    # Look for the other occurRows\n",
    "    for idx1, occurRow1 in enumerate(occurrence):\n",
    "\n",
    "        #Only look at other rows.\n",
    "        if idx != idx1 and idx1 > idx:\n",
    "            strength = sum(np.array(occurRow) & np.array(occurRow1)) #Use the & operator to check for both true. Sum everything to get number of positives. \n",
    "            newStrengthRow[idx1-idx-1] = strength #Need to adjust based on the array init\n",
    "        \n",
    "    strengthMatrix[idx] = newStrengthRow\n",
    "\n",
    "\n",
    "# for i in strengthMatrix:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#The idea to check if both array have true at the same index. \n",
    "\n",
    "test1 = [True, True, False]\n",
    "test2 = [True, True, False]\n",
    "\n",
    "print(sum(np.array(test1) & np.array(test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Themes\n",
       "clinical         8\n",
       "psychodynamic    8\n",
       "self-help        7\n",
       "social           6\n",
       "behavioural      6\n",
       "cognitive        6\n",
       "developmental    3\n",
       "personality      3\n",
       "biological       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Themes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creatlng a color list for different themes\n",
    "\n",
    "df[\"ThemeColor\"] = df[\"Themes\"].map({\"clinical\": \"#03A9F4\", \"psychodynamic\" : \"#7B1FA2\", \"self-help\": \"#7CB342\", \"social\" : \"#FFB300\", \"behavioural\": \"#6D4C41\", \"cognitive\" : \"#546E7A\", \"developmental\" : \"#3F51B5\", \"personality\": \"#D32F2F\", \"biological\": \"#33691E\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Original Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Additional Keywords</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>Themes</th>\n",
       "      <th>Additional Keywords List</th>\n",
       "      <th>ThemeColor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Understanding Human Nature</td>\n",
       "      <td>1927</td>\n",
       "      <td>Alfred Adler</td>\n",
       "      <td>Originally published in 1927 this book attempt...</td>\n",
       "      <td>inferiority complex, character</td>\n",
       "      <td>development, goal</td>\n",
       "      <td>3.96</td>\n",
       "      <td>224</td>\n",
       "      <td>Fawcett</td>\n",
       "      <td>449308332</td>\n",
       "      <td>9780449308332</td>\n",
       "      <td>developmental</td>\n",
       "      <td>[development, goal]</td>\n",
       "      <td>#3F51B5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Nature of Prejudice</td>\n",
       "      <td>1954</td>\n",
       "      <td>Gordon W. Allport</td>\n",
       "      <td>With profound insight into the complexities of...</td>\n",
       "      <td>prejudice, race, discrimination</td>\n",
       "      <td>violence, rationality</td>\n",
       "      <td>4.24</td>\n",
       "      <td>575</td>\n",
       "      <td>Basic Books</td>\n",
       "      <td>201001799</td>\n",
       "      <td>9780201001792</td>\n",
       "      <td>social</td>\n",
       "      <td>[violence, rationality]</td>\n",
       "      <td>#FFB300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-Efficacy: The Exercise of Control</td>\n",
       "      <td>1997</td>\n",
       "      <td>Albert Bandura</td>\n",
       "      <td>With over 20 years of research by renowned psy...</td>\n",
       "      <td>self-system, self-esteem, self-efficacy</td>\n",
       "      <td>goal, self</td>\n",
       "      <td>4.12</td>\n",
       "      <td>604</td>\n",
       "      <td>Worth Publishers</td>\n",
       "      <td>716728508</td>\n",
       "      <td>9780716728504</td>\n",
       "      <td>behavioural</td>\n",
       "      <td>[goal, self]</td>\n",
       "      <td>#6D4C41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Gift of Fear: Survival Signals That Protec...</td>\n",
       "      <td>1997</td>\n",
       "      <td>Gavin de Becker</td>\n",
       "      <td>A date won't take \"no\" for an answer. The new ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>violence, intuition, crime</td>\n",
       "      <td>4.18</td>\n",
       "      <td>352</td>\n",
       "      <td>Bloomsbury Publishing PLC</td>\n",
       "      <td>747538352</td>\n",
       "      <td>9780747538356</td>\n",
       "      <td>social</td>\n",
       "      <td>[violence, intuition, crime]</td>\n",
       "      <td>#FFB300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Games People Play</td>\n",
       "      <td>1964</td>\n",
       "      <td>Eric Berne</td>\n",
       "      <td>Forty years ago, Games People Play revolutioni...</td>\n",
       "      <td>stroke, transactional analysis, games</td>\n",
       "      <td>social</td>\n",
       "      <td>3.74</td>\n",
       "      <td>192</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>345032799</td>\n",
       "      <td>9780345032799</td>\n",
       "      <td>social</td>\n",
       "      <td>[social]</td>\n",
       "      <td>#FFB300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                         Understanding Human Nature   \n",
       "1                            The Nature of Prejudice   \n",
       "2             Self-Efficacy: The Exercise of Control   \n",
       "3  The Gift of Fear: Survival Signals That Protec...   \n",
       "4                                  Games People Play   \n",
       "\n",
       "  Original Publication Year             Author  \\\n",
       "0                      1927       Alfred Adler   \n",
       "1                      1954  Gordon W. Allport   \n",
       "2                      1997     Albert Bandura   \n",
       "3                      1997    Gavin de Becker   \n",
       "4                      1964         Eric Berne   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Originally published in 1927 this book attempt...   \n",
       "1  With profound insight into the complexities of...   \n",
       "2  With over 20 years of research by renowned psy...   \n",
       "3  A date won't take \"no\" for an answer. The new ...   \n",
       "4  Forty years ago, Games People Play revolutioni...   \n",
       "\n",
       "                                  Keywords         Additional Keywords  \\\n",
       "0           inferiority complex, character           development, goal   \n",
       "1          prejudice, race, discrimination       violence, rationality   \n",
       "2  self-system, self-esteem, self-efficacy                  goal, self   \n",
       "3                                     fear  violence, intuition, crime   \n",
       "4    stroke, transactional analysis, games                      social   \n",
       "\n",
       "   Average Rating  Number of Pages                  Publisher       ISBN  \\\n",
       "0            3.96              224                    Fawcett  449308332   \n",
       "1            4.24              575                Basic Books  201001799   \n",
       "2            4.12              604           Worth Publishers  716728508   \n",
       "3            4.18              352  Bloomsbury Publishing PLC  747538352   \n",
       "4            3.74              192                    Penguin  345032799   \n",
       "\n",
       "          ISBN13         Themes      Additional Keywords List ThemeColor  \n",
       "0  9780449308332  developmental           [development, goal]    #3F51B5  \n",
       "1  9780201001792         social       [violence, rationality]    #FFB300  \n",
       "2  9780716728504    behavioural                  [goal, self]    #6D4C41  \n",
       "3  9780747538356         social  [violence, intuition, crime]    #FFB300  \n",
       "4  9780345032799         social                      [social]    #FFB300  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possible viz library: https://pyvis.readthedocs.io/en/latest/documentation.html, https://github.com/imohitmayank/jaal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting the title (popup)\n",
    "    \n",
    "import textwrap\n",
    "\n",
    "def formatTitle(title, year, author, summary, keywords, averageRating):\n",
    "\n",
    "    wrapped_summary = textwrap.fill(summary, 80)\n",
    "    return (f\"\"\"Title: {title}\n",
    "            Year: {year}\n",
    "            Author: {author}\n",
    "            Average Rating (Goodreads): {averageRating}\n",
    "            Keywords: {keywords}\n",
    "            Summary: {wrapped_summary}\n",
    "    \"\"\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = '''\n",
    "    {\n",
    "        \"autoResize\": false,\n",
    "        \"physics\": {\n",
    "            \"maxVelocity\" : 5,\n",
    "            \"timestep\" : 0.25,\n",
    "            \"barnesHut\" : {\n",
    "                \"springLength\": 30,\n",
    "                \"springConstant\": 0.01,\n",
    "                \"centralGravity\" : 0.5\n",
    "            }\n",
    "        },\n",
    "        \"layout\" : {\n",
    "            \"randomSeed\" : 62,\n",
    "            \"clusterThreshold\" : 50\n",
    "        }, \n",
    "        \"interaction\": {\n",
    "            \"navigationButtons\" : true\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "net = network.Network(notebook= True, select_menu= True, filter_menu= True, neighborhood_highlight= True)\n",
    "\n",
    "#Need to loop, so we can set more properties for nodes\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "    net.add_node(n_id = idx, label = row[\"Title\"], color = row[\"ThemeColor\"], title = formatTitle(row['Title'], row['Original Publication Year'], row['Author'],row['Summary'], row['Keywords'], row['Average Rating']), font = {\"face\" : \"tahoma\", \"size\" : 15},  widthConstraint = 200, physics = True)   \n",
    "\n",
    "#Add edges\n",
    "#For each source node\n",
    "for idx, row in enumerate(strengthMatrix):\n",
    "    \n",
    "    #Add a link to a destination node if its not 0. \n",
    "    for idx1, val in enumerate(row):\n",
    "        \n",
    "        #For the destination node, since the strength matrix is only filled to the diagonal, the indexing must offset the start position is actually the source.\n",
    "        if val != 0:\n",
    "\n",
    "            #print(f\" idx/source: {idx}, idx1: {idx1}, destination: {idx+idx1+1}\")\n",
    "            net.add_edge(int(idx), int(idx+idx1+1), value = int(val), color = { \"color\": '#607D8B', \"highlight\" : \"#000000\" } , physics = True, scaling = {\"max\" : 5}, length = 300, dashes = True, chosen = {\"edge.dashes\" : False})\n",
    "\n",
    "\n",
    "net.set_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add legend: https://github.com/WestHealth/pyvis/issues/50\n",
    "x = -2000\n",
    "y = -250\n",
    "step = 100\n",
    "numOfColors = len(list(df[\"Themes\"].unique()))\n",
    "legendLabels = [\"clinical\",\"psychodynamic\" ,\"self-help\", \"social\" , \"behavioural\", \"cognitive\" , \"developmental\", \"personality\", \"biological\"]\n",
    "legendColor = [\"#03A9F4\",\"#7B1FA2\", \"#7CB342\", \"#FFB300\", \"#6D4C41\", \"#546E7A\", \"#3F51B5\",  \"#D32F2F\", \"#33691E\"]\n",
    "xCoords = [x] * numOfColors\n",
    "yCoords = [ y + (i * step) for i in range(numOfColors)]\n",
    "for i in range(numOfColors):\n",
    "    net.add_node(legendLabels[i], label = legendLabels[i], color = legendColor[i], x = xCoords[i], y = yCoords[i], physics = False, fixed = {x : False, y : False}, shape = 'square' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PsychGraph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"PsychGraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2cb674b7ed0>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net.toggle_physics(True)\n",
    "net.show(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commented out the this part because it makes the center node jittery. The physics does not work well because the node keeps moving straight back to center position upon any interaction with other nodes. \n",
    "#Lets adjust the center of the graph to a node which has the most connections.\n",
    "# import math\n",
    "# adjList = net.get_adj_list()\n",
    "# max = -math.inf\n",
    "# maxNode = None\n",
    "# for key in adjList:\n",
    "#     if len(adjList[key]) > max:\n",
    "#         max = len(adjList[key])\n",
    "#         maxNode = key\n",
    "\n",
    "# print(f'The node id with the highest degree of {max} is {maxNode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = network.Network(notebook= True, select_menu= True, filter_menu= True, neighborhood_highlight= True)\n",
    "\n",
    "# #Need to loop, so we can set more properties for nodes\n",
    "# for idx, row in df.iterrows():\n",
    "\n",
    "#     #if the node is the highest degree:\n",
    "#     if idx == maxNode:\n",
    "#         print(idx)\n",
    "#         print(row[\"Title\"])\n",
    "#         net.add_node(n_id = idx, x = 0, y = 0,label = row[\"Title\"], color = row[\"ThemeColor\"], title = formatTitle(row['Title'], row['Original Publication Year'], row['Author'],row['Summary'], row['Keywords'], row['Average Rating']), font = {\"face\" : \"tahoma\", \"size\" : 15},  widthConstraint = 200, physics = True)\n",
    "\n",
    "#     else:\n",
    "#         net.add_node(n_id = idx, label = row[\"Title\"], color = row[\"ThemeColor\"], title = formatTitle(row['Title'], row['Original Publication Year'], row['Author'],row['Summary'], row['Keywords'], row['Average Rating']), font = {\"face\" : \"tahoma\", \"size\" : 15},  widthConstraint = 200, physics = True)\n",
    "\n",
    "    \n",
    "\n",
    "# #Add edges\n",
    "# #For each source node\n",
    "# for idx, row in enumerate(strengthMatrix):\n",
    "    \n",
    "#     #Add a link to a destination node if its not 0. \n",
    "#     for idx1, val in enumerate(row):\n",
    "        \n",
    "#         #For the destination node, since the strength matrix is only filled to the diagonal, the indexing must offset the start position is actually the source.\n",
    "#         if val != 0:\n",
    "\n",
    "#             #print(f\" idx/source: {idx}, idx1: {idx1}, destination: {idx+idx1+1}\")\n",
    "#             net.add_edge(int(idx), int(idx+idx1+1), value = int(val), color = { \"color\": '#607D8B', \"highlight\" : \"#000000\" } , physics = True, scaling = {\"max\" : 5}, length = 300, dashes = True, chosen = {\"edge.dashes\" : False})\n",
    "\n",
    "\n",
    "# #Change options for the graph\n",
    "# net.set_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To add legend: https://github.com/WestHealth/pyvis/issues/50\n",
    "# x = -2000\n",
    "# y = -250\n",
    "# step = 100\n",
    "# numOfColors = len(list(df[\"Themes\"].unique()))\n",
    "# legendLabels = [\"clinical\",\"psychodynamic\" ,\"self-help\", \"social\" , \"behavioural\", \"cognitive\" , \"developmental\", \"personality\", \"biological\"]\n",
    "# legendColor = [\"#03A9F4\",\"#7B1FA2\", \"#7CB342\", \"#FFB300\", \"#6D4C41\", \"#546E7A\", \"#3F51B5\",  \"#D32F2F\", \"#33691E\"]\n",
    "# xCoords = [x] * numOfColors\n",
    "# yCoords = [ y + (i * step) for i in range(numOfColors)]\n",
    "# for i in range(numOfColors):\n",
    "#     net.add_node(legendLabels[i], label = legendLabels[i], color = legendColor[i], x = xCoords[i], y = yCoords[i], physics = False, fixed = {x : False, y : False}, shape = 'square' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #net.toggle_physics(True)\n",
    "# net.show(\"PsychGraph.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
